{"cells":[{"cell_type":"markdown","source":["# Installing Components\n","\n","Installing necessary libraries and frameworks, such as LlamaIndex, to utilize retrieval-augmented capabilities in your environment"],"metadata":{"id":"HSoIdZFpjUgG"}},{"cell_type":"markdown","source":["### Installation\n","* Before using the library, you must install it in your environment:\n","Use the command !pip install llama-index to install."],"metadata":{"id":"B0Ve6AdXlWvF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9mI5bJ6E5yEJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714894999534,"user_tz":-480,"elapsed":82510,"user":{"displayName":"Ace Jr Canacan","userId":"05288900807244843953"}},"outputId":"4b4eb745-1c42-4a1f-9f3b-8fdd5ac19cef"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/15.4 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m598.7/598.7 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n","weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["%pip install llama-index-multi-modal-llms-gemini --quiet\n","%pip install llama-index-vector-stores-chroma --quiet\n","%pip install llama-index-embeddings-gemini --quiet\n","%pip install llama-index-llms-gemini --quiet\n","%pip install llama-index-readers-file --quiet"]},{"cell_type":"markdown","source":["### Importing Components\n","* Once installed, import the necessary components of the library: Example: from llama_index.prompts import PromptTemplate"],"metadata":{"id":"9nbZl_j8lUrg"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nNqnyRSF5olt"},"outputs":[],"source":["# Import necessary modules from llama_index package for creating and managing vector stores and embeddings\n","from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings, StorageContext\n","\n","# Import GeminiEmbedding from llama_index for embedding generation\n","from llama_index.embeddings.gemini import GeminiEmbedding\n","\n","# Import Gemini from llama_index for handling Gemini large language models (LLMs)\n","from llama_index.llms.gemini import Gemini\n","\n","# Import ChromaVectorStore from llama_index for handling vector storage specific to Chroma implementation\n","from llama_index.vector_stores.chroma import ChromaVectorStore\n","\n","# Import the llama_index module to access its functionalities\n","import llama_index\n","\n","# Import chromadb module for working with Chroma database functionalities\n","import chromadb\n","\n","# Import the os module for operating system dependent functionality\n","import os\n"]},{"cell_type":"markdown","source":["# Initializing AI Model\n","\n","Configuring and setting up the AI model (like Gemini) to prepare it for embedding and querying processes within the LlamaIndex framework.\n"],"metadata":{"id":"dLX9UW2-jjYb"}},{"cell_type":"markdown","source":["### Gemini AI Model:\n","  * For our project, we utilize Google's Gemini, a versatile generative AI model. Gemini supports various applications such as chatting, embedding generation, image, and audio processing."],"metadata":{"id":"aPtuUJV0lucW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nkn_HcvHzOIm"},"outputs":[],"source":["# Define a variable GOOGLE_API_KEY with the API key string as its value. Replace the existing key with your actual Google API key.\n"]},{"cell_type":"markdown","source":["### API Access:\n","  * API Key: Access to Gemini requires a Google API key. This key enables interaction with Gemini's functionalities."],"metadata":{"id":"HZZm7SYblbEo"}},{"cell_type":"code","source":["# Set the environment variable \"GOOGLE_API_KEY\" to the value stored in the GOOGLE_API_KEY variable.\n"],"metadata":{"id":"f9HFM5oMldCx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Loading\n","\n","Reading and ingesting data from various formats into LlamaIndex to convert into a format suitable for AI processing"],"metadata":{"id":"-hHxfmS8jt8G"}},{"cell_type":"markdown","source":["### Data Loading:\n","  * LlamaIndex supports various data formats including CSV, DOCX, EPUBs, HTML, Jupyter Notebooks, and more, facilitating versatile data handling capabilities.\n","  * For simplicity, you can use a directory reader to load data directly from a folder, ideal for processing multiple files efficiently, such as PDFs."],"metadata":{"id":"LDq1KyIdl-Xb"}},{"cell_type":"code","source":["# Create a SimpleDirectoryReader to read documents from a specified directory at '/content/data'.\n"],"metadata":{"id":"8jsP9ps9dn5c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Storing\n","\n","Securing the transformed data into an organized storage system, ensuring it's readily accessible for indexing and querying"],"metadata":{"id":"YFOQCKXpj1Iw"}},{"cell_type":"markdown","source":["### Chroma Client:\n","  * The Chroma Client acts as a mediator, facilitating communication between user commands and the system."],"metadata":{"id":"_V3Wv4uzmH03"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LeS3sNSe5rML"},"outputs":[],"source":["# Create an instance of EphemeralClient from the chromadb module.\n"]},{"cell_type":"markdown","source":["### Chroma Collections:\n","  * Collections in Chroma function similarly to folders on a computer, organizing your embeddings efficiently.\n","  * These collections can be created or accessed using identifiers, which means you can retrieve or initialize them as needed."],"metadata":{"id":"opTOA33zmI6r"}},{"cell_type":"code","source":["# Use the chroma_client to access or create a new collection named \"spongebob_data\".\n"],"metadata":{"id":"-IeqL3BamATF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Vector Store Integration:\n","  * Once embeddings are placed in a collection, they are managed through a vector store.\n","  * This system supports operations like manipulation and retrieval of embeddings, with various vector stores available that differ in features and performance advantages."],"metadata":{"id":"Nwjcxil6mINb"}},{"cell_type":"code","source":["# Initialize a ChromaVectorStore using the chroma_collection.\n","\n"],"metadata":{"id":"L6vFV7N1mAt-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Indexing\n","\n","Creating a searchable index from the stored data to facilitate efficient retrieval based on AI-generated embeddings"],"metadata":{"id":"NrwBbdXXkFvT"}},{"cell_type":"markdown","source":["### Setting Up the Embedding Model:\n","  * Through LlamaIndex settings, you can specify which AI model to utilize for embeddings.\n","  * For instance, selecting the 'GeminiEmbedding' model allows you to define the model details and integrate the necessary Google API key for operation."],"metadata":{"id":"y8iFVfaEmsP9"}},{"cell_type":"code","source":["# Set the embedding model in the Settings to use the GeminiEmbedding class.\n","# Here, we configure the system to use a specific pre-trained model located at \"models/embedding-001\"."],"metadata":{"id":"LDgqb6z9p4_2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Configuring API Settings:\n","  * Further customization of settings includes specifying the API key for the Gemini model, ensuring secure and effective communication with Google's AI services."],"metadata":{"id":"ZGj28VRcmsbJ"}},{"cell_type":"code","source":["# Set the API key in the overall settings\n"],"metadata":{"id":"QQzKnFGCmk2D"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Storage Configuration:\n","  * The 'StorageContext' is set up, typically with default parameters, to determine how embeddings are stored. This setting ties directly into how the data is managed and retrieved."],"metadata":{"id":"hgiMLX8kmtFI"}},{"cell_type":"code","source":["# Initialize a StorageContext using default settings with the specified vector_store.\n"],"metadata":{"id":"ntlxaM6omlF5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Creating and Managing the Index:\n","  * This function reads from the specified documents (PDF files in this case) and applies the predefined storage settings to organize, generate, and store the generated embeddings ."],"metadata":{"id":"7DirjZjkmtaG"}},{"cell_type":"code","source":["# Create a VectorStoreIndex from the loaded documents.\n"],"metadata":{"id":"zVOxeuKvmlbg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Querying\n","\n","Executing specific inquiries against the indexed data using a query engine to extract relevant information and insights"],"metadata":{"id":"hfoj_HRllKEU"}},{"cell_type":"markdown","source":["### Setting Up the Query Engine:\n","  * To interact with the indexed data, set up a query engine using the index.as_query_engine function. This allows you to specify parameters such as similarity_top_k, which helps determine the most relevant data points based on your query."],"metadata":{"id":"Nxoy2KzZm69A"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"GmrjshWp5uQs"},"outputs":[],"source":["# Convert the previously created index into a query engine.\n"]},{"cell_type":"markdown","source":["### Executing Queries:\n","  * With the query engine in place, you can start querying the data. Simply place your specific questions within the query function to retrieve relevant information from your data."],"metadata":{"id":"tmsvUu8-m8y5"}},{"cell_type":"code","source":["# Use the query engine to perform a search with the question about the difference between valleys and hills.\n","\n","\n","# Print the response obtained from the query engine.\n"],"metadata":{"id":"oonUKxH7m-BM","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1714895134408,"user_tz":-480,"elapsed":4374,"user":{"displayName":"Ace Jr Canacan","userId":"05288900807244843953"}},"outputId":"f213a177-7687-4b3d-d050-908d40ca2656"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SpongeBob became a fashion phenomenon in Egypt after the Egyptian Revolution of 2011.\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"1BvUsBpp1Z0DnJe-8soX-pYZUmuCzMgq6","timestamp":1714895144778},{"file_id":"1unUKYbRcNJl-p5CJT0p39Svj98fDyDbx","timestamp":1714894550381},{"file_id":"1jjTpadfkYQRmXHGnOYytaWtYuEidgYij","timestamp":1714806753197}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}